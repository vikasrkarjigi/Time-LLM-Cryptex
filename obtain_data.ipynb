{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4cdc18",
   "metadata": {},
   "source": [
    "This "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c8707",
   "metadata": {},
   "source": [
    "\"\"\"The code in this file is used to obtain the data from the yfinance API and save it to a csv file.\n",
    "\n",
    "Run all the code in this file to obtain the data from the yfinance API and save it to a csv file.\n",
    "\n",
    "Just edit the dates filepaths and names\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5526684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def convert_to_returns(data, keep_high_low=False, keep_volume=True, log_returns=False):\n",
    "    \"\"\"\n",
    "    Convert data to returns.\n",
    "\n",
    "    args:\n",
    "        data: pandas DataFrame with \"close\" and \"volume\" columns\n",
    "        log_returns: bool, if True, the data is converted to log returns\n",
    "        keep_high_low: bool, if True, the high and low prices are kept\n",
    "        keep_volume: bool, if True, the volume column is kept\n",
    "    returns:\n",
    "        pandas DataFrame with \"returns\" and \"volume\" columns\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame({\"close\": data[\"close\"], \"volume\": data[\"volume\"], \"timestamp\": data[\"timestamp\"]})\n",
    "    if log_returns:\n",
    "        data[\"returns\"] = np.log(data[\"close\"] / data[\"close\"].shift(1))\n",
    "    else:\n",
    "        data[\"returns\"] = data[\"close\"] / data[\"close\"].shift(1) - 1\n",
    "    \n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "    final_data = pd.DataFrame()\n",
    "    final_data['returns'] = data['returns']\n",
    "\n",
    "\n",
    "    if keep_high_low:\n",
    "        final_data[\"high\"] = data[\"high\"]\n",
    "        final_data[\"low\"] = data[\"low\"]\n",
    "\n",
    "    if keep_volume:\n",
    "        final_data[\"volume\"] = data[\"volume\"]\n",
    "\n",
    "    final_data[\"timestamp\"] = data[\"timestamp\"]\n",
    "\n",
    "\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def convert_back_to_candlesticks(candlesticks, predicted_returns):\n",
    "    \"\"\"\n",
    "    Convert returns data back to candlesticks. This is used to backtest the model.\n",
    "\n",
    "    args:\n",
    "        data: pandas DataFrame with \"returns\" and \"volume\" columns\n",
    "        \"\"\"\n",
    "    \n",
    "    # Make a copy of the candlesticks data\n",
    "    result = candlesticks.copy()\n",
    "    \n",
    "    # Get the last known close price before predictions start\n",
    "    last_close = result.loc[result.index[predicted_returns['returns_predicted_1'].first_valid_index()-1], 'close']\n",
    "    \n",
    "    # Calculate predicted close prices from returns\n",
    "    for i in range(1, 3):  # For returns_predicted_1 and returns_predicted_2\n",
    "        col = f'returns_predicted_{i}'\n",
    "        if col in predicted_returns.columns:\n",
    "            # Calculate cumulative returns \n",
    "            pred_close = last_close * (1 + predicted_returns[col])\n",
    "            # Rename column\n",
    "            result[f'close_predicted_{i}'] = pred_close\n",
    "\n",
    "    # Convert unix timestamp to UTC datetime\n",
    "    result[\"timestamp\"] = pd.to_datetime(result[\"timestamp\"], unit='s', utc=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "import pandas as pd\n",
    "def agg_data(data, n_times):\n",
    "    \"\"\"\n",
    "    Aggregate OHLCV data by duplicating n times and adjusting values accordingly.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with OHLCV data\n",
    "        n_times: Number of times to duplicate the data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with aggregated data\n",
    "    \"\"\"\n",
    "    # Make a copy of original data\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate price adjustments for each duplicate\n",
    "    # We'll create slight variations around the original prices\n",
    "    variations = np.linspace(-0.001, 0.001, n_times)\n",
    "    \n",
    "    # Initialize list to store duplicated dataframes\n",
    "    dfs = []\n",
    "    \n",
    "    for i in range(n_times):\n",
    "        temp_df = df.copy()\n",
    "        \n",
    "        # Add small variations to prices\n",
    "        adjustment = 1 + variations[i]\n",
    "        temp_df['open'] = temp_df['open'] * adjustment\n",
    "        temp_df['high'] = temp_df['high'] * adjustment\n",
    "        temp_df['low'] = temp_df['low'] * adjustment\n",
    "        temp_df['close'] = temp_df['close'] * adjustment\n",
    "        \n",
    "        # Divide volume by n_times to distribute it\n",
    "        temp_df['volume'] = temp_df['volume'] / n_times\n",
    "        \n",
    "        # If there are predicted columns, apply the same price adjustment\n",
    "        pred_cols = [col for col in temp_df.columns if 'predicted' in col]\n",
    "        for col in pred_cols:\n",
    "            temp_df[col] = temp_df[col] * adjustment\n",
    "            \n",
    "        dfs.append(temp_df)\n",
    "    \n",
    "    # Concatenate all duplicated dataframes\n",
    "    result = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Sort by timestamp to maintain chronological order\n",
    "    result = result.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15136/2985823661.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download('BTC-USD', start='2024-05-01', end='2024-07-01', interval='1h')\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "df = yf.download('BTC-USD', start='2024-06-01', end='2024-07-01', interval='1h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to unix time\n",
    "df[\"Date\"] = pd.to_datetime(df.index, utc=True)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).astype(int) / 10**9\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rearranges and renames columns to be the same as the data before\n",
    "df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "df.columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc5a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to returns and save to csv\n",
    "\n",
    "data_name = \"hourly/ohlcv_h_4m_inf\"\n",
    "\n",
    "#df = convert_to_returns(df, keep_volume=False, keep_high_low=False)\n",
    "df.to_csv(f\"dataset/cryptex/{data_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"./dataset/inference.csv\")\n",
    "ohlcv_df = pd.read_csv(f\"./dataset/ohlcv_h_4m_inf.csv\")\n",
    "convert_back_to_candlesticks(df, df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
